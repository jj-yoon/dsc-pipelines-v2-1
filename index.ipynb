{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pipelines\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You've learned a substantial number of different supervised learning algorithms. Now, it's time to learn about a handy tool used to integrate these algorithms into a single manageable pipeline.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Explain how pipelines can be used to combine various parts of a machine learning workflow  \n",
    "\n",
    "## Why Use Pipelines?\n",
    "\n",
    "Pipelines are extremely useful tools to write clean and manageable code for machine learning. Recall how we start preparing our dataset: we want to clean our data, transform it, potentially use feature selection, and then run a machine learning algorithm. Using pipelines, you can do all these steps in one go!\n",
    "\n",
    "Pipeline functionality can be found in scikit-learn's `Pipeline` module. Pipelines can be coded in a very simple way:\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create the pipeline\n",
    "pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                 ('tree', DecisionTreeClassifier(random_state=123))])\n",
    "```\n",
    "\n",
    "This pipeline will ensure that first we'll apply a Min-Max scaler on our data before fitting a decision tree. However, the `Pipeline()` function above is only defining the sequence of actions to perform. In order to actually fit the model, you need to call the `.fit()` method like so: \n",
    "\n",
    "```python\n",
    "# Fit to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "Then, to score the model on test data, you can call the `.score()` method like so: \n",
    "\n",
    "```python\n",
    "# Calculate the score on test data\n",
    "pipe.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "A really good blog post on the basic ideas of pipelines can be found [here](https://www.kdnuggets.com/2017/12/managing-machine-learning-workflows-scikit-learn-pipelines-part-1.html).\n",
    "\n",
    "\n",
    "## Integrating Grid Search in Pipelines\n",
    "\n",
    "Note that the above pipeline simply creates one pipeline for a training set, and evaluates on a test set. Is it possible to create a pipeline that performs grid search? And cross-validation? Yes, it is!\n",
    "\n",
    "First, you define the pipeline in the same way as above. Next, you create a parameter grid. When this is all done, you use the function `GridSearchCV()`, which you've seen before, and specify the pipeline as the estimator and the parameter grid. You also have to define how many folds you'll use in your cross-validation. \n",
    "\n",
    "```python\n",
    "# Create the pipeline\n",
    "pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                 ('tree', DecisionTreeClassifier(random_state=123))])\n",
    "\n",
    "# Create the grid parameter\n",
    "grid = [{'tree__max_depth': [None, 2, 6, 10], \n",
    "         'tree__min_samples_split': [5, 10]}]\n",
    "\n",
    "\n",
    "# Create the grid, with \"pipe\" as the estimator\n",
    "gridsearch = GridSearchCV(estimator=pipe, \n",
    "                          param_grid=grid, \n",
    "                          scoring='accuracy', \n",
    "                          cv=5)\n",
    "\n",
    "# Fit using grid search\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the test score\n",
    "gridsearch.score(X_test, y_test)\n",
    "```\n",
    "\n",
    "An article with a detailed workflow can be found [here](https://www.kdnuggets.com/2018/01/managing-machine-learning-workflows-scikit-learn-pipelines-part-2.html).\n",
    "\n",
    "## Summary\n",
    "\n",
    "Great, this wasn't too difficult! The proof of all this is in the pudding. In the next lab, you'll use this workflow to build pipelines applying classification algorithms you have learned so far in this module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T17:02:41.436902Z",
     "start_time": "2021-12-07T17:02:36.607292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.867\n",
      "\n",
      "Model hyperparameters:\n",
      " {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 42, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "\n",
    "# Load and split the data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct pipeline\n",
    "pipe = Pipeline([('scl', StandardScaler()),\n",
    "                 ('pca', PCA(n_components=2)),\n",
    "                 ('clf', tree.DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Pipeline test accuracy\n",
    "print('Test accuracy: %.3f' % pipe.score(X_test, y_test))\n",
    "\n",
    "# Pipeline estimator params; estimator is stored as step 3 ([2]), second item ([1])\t\t\t\n",
    "print('\\nModel hyperparameters:\\n', pipe.steps[2][1].get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T17:04:16.081862Z",
     "start_time": "2021-12-07T17:04:16.050904Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.grid_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-44f99635ea67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.grid_search'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import tree\n",
    "\n",
    "# Load and split the data\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construct pipeline\n",
    "pipe = Pipeline([('scl', StandardScaler()),\n",
    "                 ('pca', PCA(n_components=2)),\n",
    "                 ('clf', tree.DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "param_range = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Set grid search params\n",
    "grid_params = [{'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__min_samples_leaf': param_range,\n",
    "                'clf__max_depth': param_range,\n",
    "                'clf__min_samples_split': param_range[1:],\n",
    "                'clf__presort': [True, False]}]\n",
    "\n",
    "# Construct grid search\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                  param_grid=grid_params,\n",
    "                  scoring='accuracy',\n",
    "                  cv=10)\n",
    "\n",
    "# Fit using grid search\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Best accuracy\n",
    "print('Best accuracy: %.3f' % gs.best_score_)\n",
    "\n",
    "# Best params\n",
    "print('\\nBest params:\\n', gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
